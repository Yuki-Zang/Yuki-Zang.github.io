---
layout: post
title: Week 9-10
---

This week I tested on temperature impacts the gpt annotation performance. I varied the temperature form 0.1 to 1.0. The following figure plots the data(score is the kohen kappa score), from which I observe that no optimal temperature works best for the gpt annotation.
![image info](/Users/yuki/Desktop/Yuki-Zang.github.io/images/performance_by_temp.png)

Meanwhile, this week I modified the MTurk once more with following features:
1). participants now need to choose either a checkbox, which says third-party, or a slider, which means either in or outgroup. The slider has five level from fan's team, likely fan's team, either, likely opponents' team, to opponents' team.
2). there's a text box under each comment so that participants now can voluntarily leave their reasoning behind the answer.
3). every masked entity is a forced question, so participants must finish labeling all the comments to submit the answer.
4). replace the city name with [CITY] and name with [NAME].
![image info](/Users/yuki/Desktop/Yuki-Zang.github.io/images/UIexample.png)

All four members in the lab tried on this updated task. Since there are multiple candicate choices (6 of them) in this task, calulating the accuracy is a trickier task. But in general people did poorly on this task with the fleiss kappa score being 0.22. However, we need to devise a wiser metrics for calculating the accuracy. Binarizing the slider might be a good idea.

Finally, I also ran the coref-resolution codes from https://github.com/shon-otmazgin/lingmess-coref. It returns a list of lists of number pairs, with the first being the start index and second being the end index. The number spans a noun/pronoun/noun phrase, and everything in the same list refers to the same entity. The following is an example (after matching the index with actual tokens):

##### doc_key: hknbn8z
The team that played today was the team I 've been expecting to pay all year .   Our D - Line was getting great pressure and our secondary was hitting guys as soon as they caught the ball . This game shows us this team is not as bad as we thought it was and capable of competing with the big boys .   We have had tons of opportunities to take advantage of games , most notably the Chiefs and Packers games , and when we do we can win ( duh ) . The game at Carolina is huge , but these last 8 games are significantly easier .
[['Our'], ['our'], ['us'], ['we'], ['We'], ['we'], ['we']]
[['guys'], ['they']]
[['The', 'team', 'that', 'played', 'today'], ['this', 'team'], ['it']]
###########################

We plan to match pronouns like they/them/their/theirs and we/us/our/ours with team names so that we have more gold labels for testing and model. From our inspection, the model works well with pairing entities but there are few occurances of the aforementioned pronouns.


This is the end of the formal DREU program, but I will continue working on this project.
